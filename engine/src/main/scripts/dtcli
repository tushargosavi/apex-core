#!/bin/bash
#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#

# Support functions
echoerr() { echo "$@" 1>&2; }
real_dir() {
  SOURCE="${1:-${BASH_SOURCE[0]}}"
  while [ -h "$SOURCE" ]; do # resolve $SOURCE until the file is no longer a symlink
    SOURCE_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
    SOURCE="$(readlink "$SOURCE")"
    [[ $SOURCE != /* ]] && SOURCE="$SOURCE_DIR/$SOURCE" # if $SOURCE was a relative symlink, we need to resolve it relative to the path where the symlink file was located
  done
  SOURCE_DIR="$( cd -P "$( dirname "$SOURCE" )" && pwd )"
  echo "$SOURCE_DIR"
}
script_dir=$(real_dir "${BASH_SOURCE[0]}")

# Create missing clirc file for current user
if [ ! -f "${HOME}/.dt/clirc" ]; then
  mkdir -p "${HOME}/.dt"
  cat >${HOME}/.dt/clirc <<EOF
# User editable dtcli settings
EOF
fi

# Load DataTorrent environment settings
for conf_dir in "${script_dir}/../conf" "$HOME/.dt"; do
    [[ -f "${conf_dir}/dt-env.sh" ]] && . "${conf_dir}/dt-env.sh"
done

# In development mode, if configuration files are not found, locate DT_HADOOP manually
if [ -z "${DT_HADOOP}" ]; then
  HADOOP_SEARCH_PATH="${HADOOP_PREFIX}/bin:${HADOOP_HOME}/bin:${PATH}:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:."
  export DT_HADOOP=`PATH=${HADOOP_SEARCH_PATH} && command -v hadoop 2>/dev/null`
fi

if [ "$DT_CLIENT_OPTS" = "" ]; then
#  DT_CLIENT_OPTS="-Xmx1024m -XX:MaxPermSize=512m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled"
  DT_CLIENT_OPTS="-Xmx1024m -XX:+UseConcMarkSweepGC -XX:+CMSClassUnloadingEnabled"
fi

export HADOOP_CLIENT_OPTS="$DT_CLIENT_OPTS"

BUILD_DIR="$( dirname "$0" )/../../../target"
if [ -z "$DT_HADOOP" ]; then
  MVN_GENERATED_PATH="$BUILD_DIR/mvn-generated-runtime-classpath"
else
  MVN_GENERATED_PATH="$BUILD_DIR/mvn-generated-runtime-classpath-no-hadoop"
fi

if [ -f "$MVN_GENERATED_PATH" ]; then
  # development launch mode
  DT_CORE_JAR="$BUILD_DIR/apex-engine.jar"
  if [ ! -f "$DT_CORE_JAR" ]; then
    echoerr "Error: Cannot find $DT_CORE_JAR";
    exit 1;
  fi
  DT_CLASSPATH="$DT_CLASSPATH:$DT_CORE_JAR"
  DT_CLASSPATH=$DT_CLASSPATH:`cat $MVN_GENERATED_PATH`
else
  # running from installation
  if [ -z "$DT_HADOOP" ]; then
    echoerr "Hadoop installation not found. Please include hadoop in PATH."
    exit 1;
  fi
  BASEDIR=$( cd ${script_dir}/..; pwd -P )
  DT_CLASSPATH=$BASEDIR/lib'/*'":${DT_CLASSPATH}"
fi

if [ -n "$DT_CLASSPATH" ]; then
  if [ -z "$HADOOP_CLASSPATH" ]; then
    export HADOOP_CLASSPATH="$DT_CLASSPATH"
  else
    export HADOOP_CLASSPATH="$HADOOP_CLASSPATH:$DT_CLASSPATH"
  fi
fi

if [ ! -x "$DT_HADOOP" ]; then
  echoerr "Warning: hadoop executable not found.  Running standalone with ${DT_JAVA:-java}."
  export CLASSPATH=$DT_CLASSPATH
  "${DT_JAVA:-java}" $DT_CLIENT_OPTS com.datatorrent.stram.cli.DTCli "$@"
else
  export HADOOP_USER_CLASSPATH_FIRST=1
  # remove hadoop and duplicate slf4j binding (bash replace is too slow)
  export HADOOP_CLASSPATH=$(echo -n "$HADOOP_CLASSPATH" | tr ":" "\n" | sed "/slf4j-log4j/d" | sed "/org\/apache\/hadoop/d" | tr "\n" ":")
  "$DT_HADOOP" com.datatorrent.stram.cli.DTCli "$@"
fi
